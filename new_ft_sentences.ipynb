{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import yaml\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import BulkWriteError\n",
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('new_ft_sentences.log')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logging.getLogger().handlers = []\n",
    "logging.getLogger('requests.packages.urllib3').setLevel(logging.WARNING)\n",
    "logging.basicConfig(\n",
    "    filename='new_ft_sentences.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for x in DB.rows.find({'pub_date': {'$gt': '20030103', '$lt': '20030107'}}):\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "# client.drop_database('new_ft_sentences')\n",
    "db_sentences = client.new_ft_sentences\n",
    "db_text = client.new_ft_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_rows(db, rows):\n",
    "    try:\n",
    "        db.rows.insert_many(rows, ordered=False)\n",
    "    except BulkWriteError as ex:\n",
    "        for err in ex.details['writeErrors']:\n",
    "            if err['code'] == 11000:\n",
    "                _id = err['op']['_id']\n",
    "                logging.info('BulkWriteError: {} - {}'.format(ex, _id))\n",
    "                global dups\n",
    "                dups += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('search_terms.yml') as search_term_file:\n",
    "    term_yaml = yaml.load(search_term_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [(search_term, original_term, term_type)]\n",
    "search_terms_aux = [\n",
    "    (t, k2, k1)\n",
    "        for k1 in term_yaml\n",
    "            for k2 in term_yaml[k1]\n",
    "                for t in term_yaml[k1][k2]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove\n",
    "remove_list = ['Become Inc', 'Indeed', 'at&t', 'Signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_terms = filter(lambda x: x[1] not in remove_list, search_terms_aux)\n",
    "slugified_terms = list(map(lambda x: (slugify(x[0]), x[1], x[2]), search_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 articles processed.\n",
      "10000 articles processed.\n",
      "20000 articles processed.\n",
      "30000 articles processed.\n",
      "40000 articles processed.\n",
      "50000 articles processed.\n",
      "60000 articles processed.\n",
      "70000 articles processed.\n",
      "80000 articles processed.\n",
      "90000 articles processed.\n",
      "100000 articles processed.\n",
      "110000 articles processed.\n",
      "120000 articles processed.\n",
      "130000 articles processed.\n",
      "140000 articles processed.\n",
      "150000 articles processed.\n",
      "160000 articles processed.\n",
      "170000 articles processed.\n",
      "180000 articles processed.\n",
      "190000 articles processed.\n",
      "200000 articles processed.\n",
      "210000 articles processed.\n",
      "220000 articles processed.\n",
      "230000 articles processed.\n",
      "240000 articles processed.\n",
      "250000 articles processed.\n",
      "260000 articles processed.\n",
      "270000 articles processed.\n",
      "280000 articles processed.\n",
      "290000 articles processed.\n",
      "300000 articles processed.\n",
      "310000 articles processed.\n",
      "320000 articles processed.\n",
      "330000 articles processed.\n",
      "340000 articles processed.\n",
      "350000 articles processed.\n",
      "360000 articles processed.\n",
      "370000 articles processed.\n",
      "380000 articles processed.\n",
      "390000 articles processed.\n",
      "400000 articles processed.\n",
      "410000 articles processed.\n",
      "420000 articles processed.\n",
      "430000 articles processed.\n",
      "440000 articles processed.\n",
      "450000 articles processed.\n",
      "460000 articles processed.\n",
      "470000 articles processed.\n",
      "480000 articles processed.\n",
      "490000 articles processed.\n",
      "500000 articles processed.\n",
      "510000 articles processed.\n",
      "520000 articles processed.\n",
      "530000 articles processed.\n",
      "540000 articles processed.\n",
      "550000 articles processed.\n",
      "560000 articles processed.\n",
      "570000 articles processed.\n",
      "580000 articles processed.\n",
      "590000 articles processed.\n",
      "600000 articles processed.\n",
      "610000 articles processed.\n",
      "620000 articles processed.\n",
      "630000 articles processed.\n",
      "640000 articles processed.\n",
      "650000 articles processed.\n",
      "660000 articles processed.\n",
      "670000 articles processed.\n",
      "680000 articles processed.\n",
      "690000 articles processed.\n",
      "700000 articles processed.\n",
      "710000 articles processed.\n",
      "720000 articles processed.\n",
      "730000 articles processed.\n",
      "740000 articles processed.\n",
      "750000 articles processed.\n",
      "760000 articles processed.\n",
      "770000 articles processed.\n",
      "780000 articles processed.\n",
      "790000 articles processed.\n",
      "800000 articles processed.\n",
      "810000 articles processed.\n",
      "820000 articles processed.\n",
      "830000 articles processed.\n",
      "840000 articles processed.\n",
      "850000 articles processed.\n",
      "860000 articles processed.\n",
      "870000 articles processed.\n",
      "880000 articles processed.\n",
      "890000 articles processed.\n",
      "900000 articles processed.\n",
      "910000 articles processed.\n",
      "920000 articles processed.\n",
      "930000 articles processed.\n",
      "CPU times: user 1h 50min 30s, sys: 11.4 s, total: 1h 50min 42s\n",
      "Wall time: 1h 51min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 0\n",
    "for article in db_text.rows.find():\n",
    "    rows = []\n",
    "    text = article['text']\n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        slugified_sentence = slugify(sentence)\n",
    "        slugified_sentence_list = slugified_sentence.split('-')\n",
    "        for slugified_term in slugified_terms:\n",
    "            if slugified_term[0] in slugified_sentence_list:\n",
    "                row = {\n",
    "                    'article_id': article['_id'],\n",
    "                    'date': article['date'],\n",
    "                    'url': article['url'],\n",
    "                    'source': article['source'],\n",
    "                    'title': article['title'],\n",
    "                    'term_category': slugified_term[2],\n",
    "                    'original_term': slugified_term[1],\n",
    "                    'search_term': slugified_term[0],\n",
    "                    'sentence': sentence,\n",
    "                }\n",
    "                rows.append(row)\n",
    "    if rows:\n",
    "        insert_rows(db_sentences, rows)\n",
    "    \n",
    "    if count % 10000 == 0:\n",
    "        print(count, 'articles processed.')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749553"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_sentences.rows.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'microsoft', 'sentence': 'and Microsoft.', '_id': ObjectId('5615738fa688eb2b8e26b299'), 'search_term': 'microsoft', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'Google', 'sentence': 'has pulled off a series of acquisitions, including the Inktomi search engine and the Overture advertising network, to emulate Google.', '_id': ObjectId('5615738fa688eb2b8e26b29a'), 'search_term': 'google', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'Google', 'sentence': \"Earlier this year it dropped the Google search service from its websites - though by Google's own reckoning, this only accounted for 3 per cent of its revenues.\", '_id': ObjectId('5615738fa688eb2b8e26b29b'), 'search_term': 'google', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'Google', 'sentence': 'Yahoo could now be better placed than Google to exploit this technology: as a web portal, with a range of other services and content partnerships, Yahoo!', '_id': ObjectId('5615738fa688eb2b8e26b29c'), 'search_term': 'google', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'Google', 'sentence': \"user spends nearly three hours a month on the company's various websites, compared with 30 minutes of the average Google user, according to Nielsen/NetRatings, an internet research company.\", '_id': ObjectId('5615738fa688eb2b8e26b29d'), 'search_term': 'google', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'microsoft', 'sentence': 'Microsoft, meanwhile, will get a boost from its traditional stronghold on the PC.', '_id': ObjectId('5615738fa688eb2b8e26b29e'), 'search_term': 'microsoft', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'microsoft', 'sentence': 'A Microsoft search engine could have two powerful advantages: it could combine internet search with a search of the PC itself, making it far easier for users to trawl things like their own e-mail at the same time that they search the web.', '_id': ObjectId('5615738fa688eb2b8e26b29f'), 'search_term': 'microsoft', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'microsoft', 'sentence': 'By bundling search with the Windows operating system, Microsoft could also guarantee itself a ready market - though at the risk of prompting a further attack from antitrust regulators.', '_id': ObjectId('5615738fa688eb2b8e26b2a0'), 'search_term': 'microsoft', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'microsoft', 'sentence': 'Google also warned its filing that Microsoft could have other powerful weapons.', '_id': ObjectId('5615738fa688eb2b8e26b2a1'), 'search_term': 'microsoft', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'Google', 'sentence': 'Google also warned its filing that Microsoft could have other powerful weapons.', '_id': ObjectId('5615738fa688eb2b8e26b2a2'), 'search_term': 'google', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'Google', 'sentence': 'It could limit access to the technology behind the widely-used Word word-processing package, for instance, to prevent Google from being able to search inside documents in the Word format.', '_id': ObjectId('5615738fa688eb2b8e26b2a3'), 'search_term': 'google', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n",
      "{'date': '20040429', 'article_id': '040429008280', 'source': 'ftcom', 'term_category': 2, 'url': 'http://search.ft.com/search/article.html?id=040429008280', 'original_term': 'Google', 'sentence': 'At the same time, Google must prove that it can keep a technological edge in a fast-changing area.', '_id': ObjectId('5615738fa688eb2b8e26b2a4'), 'search_term': 'google', 'title': \"Google's rivals in search for supremacy\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for s in db_sentences.rows.find():\n",
    "    print(s)\n",
    "    print()\n",
    "    \n",
    "    if count > 10:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for x in slugified_terms:\n",
    "#     for y in slugified_terms:\n",
    "#         if x[0] in y[0] and x[0] != y[0] and x[1] != y[1]:\n",
    "#             print(x)\n",
    "#             print(y)\n",
    "#             print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
