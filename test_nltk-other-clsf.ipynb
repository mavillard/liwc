{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Preparing Data\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bossa/tasks_export.json  bossa/tasks_runs_export.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls bossa/*json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOSSA Results\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing `results_bossa.json` to get a *dictionary* with keys the task ids, and values in as the average value of the scores. To do that, we first convert scores from categorical (`neg`, `neu`, `pos`) to a numeric scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>task_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11203</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>52775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_id   seconds  task_id score\n",
       "50      11203  0.000025    52775     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bossa_results = pd.read_json(\"bossa/tasks_runs_export.json\")\n",
    "bossa_results.rename(columns={\"created\": \"start_time\", \"id\": \"result_id\", \"info\": \"score\"}, inplace=True)\n",
    "bossa_results[['start_time']]= bossa_results[['start_time']].apply(pd.to_datetime, dayfirst=True)\n",
    "bossa_results[['finish_time']]= bossa_results[['finish_time']].apply(pd.to_datetime, dayfirst=True)\n",
    "bossa_results['score'] = pd.Categorical(bossa_results['score'], categories=['vneg', 'neg', 'neu', 'pos', 'vpos'])\n",
    "bossa_results['score'].cat.rename_categories([-2, -1, 0, 1, 2], inplace=True)\n",
    "# Normalize everything to -1, 0, 1\n",
    "# bossa_results['score'] = bossa_results['score'].astype(float).apply(lambda x: -1 if x < 0 else 1 if x > 0 else 0)\n",
    "bossa_results[\"seconds\"] = (bossa_results[\"finish_time\"] - bossa_results[\"start_time\"]).astype('timedelta64[us]') / 1e6\n",
    "bossa_results = bossa_results[[\"result_id\", \"seconds\", \"task_id\", \"score\"]]\n",
    "bossa_results.ix[[50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information about the sentence comes in a dictionary inside the cells of the serie `info`, so we expand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>52851</td>\n",
       "      <td>{u'search_words': u'founder', u'appears_in_sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_id                                               info\n",
       "50    52851  {u'search_words': u'founder', u'appears_in_sen..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bossa_tasks = pd.read_json(\"bossa/tasks_export.json\")\n",
    "bossa_tasks[['created']]= bossa_tasks[['created']].apply(pd.to_datetime, dayfirst=True)\n",
    "bossa_tasks.rename(columns={'id': 'task_id'}, inplace=True)\n",
    "bossa_tasks = bossa_tasks[['task_id', 'info']]\n",
    "bossa_tasks.ix[[50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we merge the `DataFrame` with the scores with the one containing the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>task_id</th>\n",
       "      <th>score</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11195</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>52776</td>\n",
       "      <td>2</td>\n",
       "      <td>{u'search_words': u'executive', u'appears_in_s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_id   seconds  task_id  score  \\\n",
       "50      11195  0.000021    52776      2   \n",
       "\n",
       "                                                 info  \n",
       "50  {u'search_words': u'executive', u'appears_in_s...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bossa_tasks_scores = pd.merge(bossa_results, bossa_tasks, on='task_id')\n",
    "bossa_tasks_scores.ix[[50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now expand the column `info` into as many new columns as keys has the dictionary `info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'search_words',\n",
       " u'appears_in_sentence',\n",
       " u'url',\n",
       " u'media',\n",
       " u'appears_in_noun_phrases',\n",
       " u'noun_phrases',\n",
       " u'sentence_id',\n",
       " u'text',\n",
       " u'sentence',\n",
       " u'pub_date',\n",
       " u'is_company']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bossa_tasks_scores.ix[50].info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>task_id</th>\n",
       "      <th>score</th>\n",
       "      <th>search_words</th>\n",
       "      <th>appears_in_sentence</th>\n",
       "      <th>url</th>\n",
       "      <th>media</th>\n",
       "      <th>appears_in_noun_phrases</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>is_company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11195</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>52776</td>\n",
       "      <td>2</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>http://dealbook.nytimes.com/2013/05/17/a-toeho...</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0</td>\n",
       "      <td>[chinese investors, overseas companies, politi...</td>\n",
       "      <td>14</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>2013-05-17T11:47:51Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>11205</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>52776</td>\n",
       "      <td>-1</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>http://dealbook.nytimes.com/2013/05/17/a-toeho...</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0</td>\n",
       "      <td>[chinese investors, overseas companies, politi...</td>\n",
       "      <td>14</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>2013-05-17T11:47:51Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>11207</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>52776</td>\n",
       "      <td>1</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>http://dealbook.nytimes.com/2013/05/17/a-toeho...</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0</td>\n",
       "      <td>[chinese investors, overseas companies, politi...</td>\n",
       "      <td>14</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>2013-05-17T11:47:51Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>11209</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>52776</td>\n",
       "      <td>-2</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>http://dealbook.nytimes.com/2013/05/17/a-toeho...</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0</td>\n",
       "      <td>[chinese investors, overseas companies, politi...</td>\n",
       "      <td>14</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>2013-05-17T11:47:51Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_id   seconds  task_id  score search_words appears_in_sentence  \\\n",
       "50      11195  0.000021    52776      2    executive                   0   \n",
       "51      11205  0.000018    52776     -1    executive                   0   \n",
       "52      11207  0.000017    52776      1    executive                   0   \n",
       "53      11209  0.000017    52776     -2    executive                   0   \n",
       "\n",
       "                                                  url media  \\\n",
       "50  http://dealbook.nytimes.com/2013/05/17/a-toeho...   nyt   \n",
       "51  http://dealbook.nytimes.com/2013/05/17/a-toeho...   nyt   \n",
       "52  http://dealbook.nytimes.com/2013/05/17/a-toeho...   nyt   \n",
       "53  http://dealbook.nytimes.com/2013/05/17/a-toeho...   nyt   \n",
       "\n",
       "   appears_in_noun_phrases                                       noun_phrases  \\\n",
       "50                       0  [chinese investors, overseas companies, politi...   \n",
       "51                       0  [chinese investors, overseas companies, politi...   \n",
       "52                       0  [chinese investors, overseas companies, politi...   \n",
       "53                       0  [chinese investors, overseas companies, politi...   \n",
       "\n",
       "   sentence_id                                               text  \\\n",
       "50          14  Chinese investors are increasingly opting to b...   \n",
       "51          14  Chinese investors are increasingly opting to b...   \n",
       "52          14  Chinese investors are increasingly opting to b...   \n",
       "53          14  Chinese investors are increasingly opting to b...   \n",
       "\n",
       "                                             sentence              pub_date  \\\n",
       "50  Chinese investors are increasingly opting to b...  2013-05-17T11:47:51Z   \n",
       "51  Chinese investors are increasingly opting to b...  2013-05-17T11:47:51Z   \n",
       "52  Chinese investors are increasingly opting to b...  2013-05-17T11:47:51Z   \n",
       "53  Chinese investors are increasingly opting to b...  2013-05-17T11:47:51Z   \n",
       "\n",
       "   is_company  \n",
       "50          0  \n",
       "51          0  \n",
       "52          0  \n",
       "53          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def json_to_series(info):\n",
    "    keys, values = zip(*info.iteritems())\n",
    "    return pd.Series(values, index=keys)\n",
    "\n",
    "bossa_info = bossa_tasks_scores[\"info\"].apply(json_to_series)\n",
    "bossa_info.reset_index()\n",
    "bossa = pd.concat([bossa_tasks_scores, bossa_info], axis=1)\n",
    "bossa.pop(\"info\")\n",
    "# bossa['id'] = bossa['id'].astype(float)\n",
    "bossa.ix[50:53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now aggregate calculating the average per `sentence_id` using a group by. In the process, we lose the source of the data, that's why we first have to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bossa.to_csv(\"sentiment/scores_ungrouped.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we aggregate and create a new `DataFrame` for the different sentences and their score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score    8996\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'We must hope after so much prevarication that this time Google's proposals represent a genuine attempt to address the concerns identified,' said David Wood, the legal counsel for Icomp, an industry group backed by Microsoft and a number of other companies.</th>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'We must push our leaders to step up and commit to action,' said Hugh Evans, the founder and chief executive of the charity.</th>\n",
       "      <td>-0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'We need them to tell the story of how we are making decisions and putting the organization together,' said George Postolos, the Astros' president and chief executive, who added that the team would not want a broadcaster who was uncomfortable explaining the front office's strategy.</th>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                               score\n",
       "sentence                                                                                                                                                                                                                                                                                            \n",
       "'We must hope after so much prevarication that this time Google's proposals represent a genuine attempt to address the concerns identified,' said David Wood, the legal counsel for Icomp, an industry group backed by Microsoft and a number of other companies.                          -0.333333\n",
       "'We must push our leaders to step up and commit to action,' said Hugh Evans, the founder and chief executive of the charity.                                                                                                                                                               -0.285714\n",
       "'We need them to tell the story of how we are making decisions and putting the organization together,' said George Postolos, the Astros' president and chief executive, who added that the team would not want a broadcaster who was uncomfortable explaining the front office's strategy. -0.666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = bossa.groupby(['sentence'])[['score']].aggregate(np.average)\n",
    "sentences.to_csv(\"sentiment/scores.csv\", encoding=\"utf8\")\n",
    "print sentences.count()\n",
    "sentences[1001:1004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority(series): #receives a Pandas Series\n",
    "    return Counter(map(lambda x: 1 if x > 0 else -1 if x < 0 else 0, series)).most_common(1)[0][0]\n",
    "\n",
    "# score_calculate = np.average\n",
    "score_calculate = majority\n",
    "\n",
    "sentences = bossa.groupby(['sentence'])[['score']].aggregate(score_calculate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Classifier\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the tranining and testing sets (data and labels) from a randomized version of the set of assessed sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    8996\n",
       "score       8996\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.reset_index().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could consider 3 classes, but it toruns out that using binary classficication seems to produce better results. Still, try multi-classs classifiers is something worth trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_scores = sentences.reset_index()\n",
    "scores = raw_scores\n",
    "# scores = scores[scores.score!=0]  # We ignore the neutral sentences\n",
    "# scores['sentiment'] = scores['score'].apply(lambda s: 'pos' if s > 0 else 'neg')\n",
    "scores['sentiment'] = scores['score'].apply(lambda s: 'pos' if s > 0 else 'neg' if s < 0 else 0)\n",
    "# percentage = 0.85  #  percentage for training, rest for for testing\n",
    "# # We split to have enough representativenesss for both positive and negative sentiments\n",
    "# sent_min = min(\n",
    "#     scores[scores.sentiment=='pos'].sentiment.count(),\n",
    "#     scores[scores.sentiment=='neg'].sentiment.count(),\n",
    "# )\n",
    "# scores = scores[[\"sentence\", \"sentiment\"]]\n",
    "# train_data = np.array([])\n",
    "# train_labels = np.array([])\n",
    "# test_data = np.array([])\n",
    "# test_labels = np.array([])\n",
    "# for sent in ('pos', 'neg'):\n",
    "#     sent_scores = scores[scores['sentiment']==sent]\n",
    "#     sent_scores = sent_scores.reindex(np.random.permutation(sent_scores.index))\n",
    "#     sent_sentences_count = int(sent_scores['sentence'].count())\n",
    "#     sent_train = sent_scores[[\"sentence\", \"sentiment\"]][:int(sent_sentences_count * percentage)]\n",
    "#     sent_test = sent_scores[[\"sentence\", \"sentiment\"]][int(sent_sentences_count * percentage) + 1:]\n",
    "#     print sent, sent_min, sent_train.sentiment.count(), sent_test.sentiment.count()\n",
    "#     train_data = np.append(train_data, sent_train[\"sentence\"])\n",
    "#     train_labels = np.append(train_labels, sent_train[\"sentiment\"])\n",
    "#     test_data = np.append(test_data, sent_test[\"sentence\"])\n",
    "#     test_labels = np.append(test_labels, sent_test[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "document_df = scores[['sentence', 'sentiment']]\n",
    "document_df = document_df.reindex(np.random.permutation(document_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>\"The world has changed; we expect to see membe...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>One of the first things the new designer, Hedi...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>'We try and curate the experience so it's not ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>Seven years ago, after living in London, Montr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>He added that while many in the news media bel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence sentiment\n",
       "62    \"The world has changed; we expect to see membe...       pos\n",
       "5983  One of the first things the new designer, Hedi...       pos\n",
       "1022  'We try and curate the experience so it's not ...       pos\n",
       "6496  Seven years ago, after living in London, Montr...         0\n",
       "3619  He added that while many in the news media bel...         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_documents = [(r[1]['sentence'], r[1]['sentiment']) for r in document_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_file = open('positive-words.txt')\n",
    "all_pos_words = [w.strip().lower() for w in pos_file]\n",
    "\n",
    "neg_file = open('negative-words.txt')\n",
    "all_neg_words = [w.strip().lower() for w in neg_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_terms_f = open('search_terms.txt')\n",
    "search_terms = []\n",
    "for t in search_terms_f:\n",
    "    l = t.strip().split()\n",
    "    search_terms.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stopwords_english\n",
    "stopwords_english = stopwords.words('english')\n",
    "#stopwords_domain\n",
    "stopwords_domain = search_terms + [\"'s\", '--']\n",
    "#stopwords_english\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features1(document):      \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = word in document_words\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features2(document):      \n",
    "    document_words = list(document)\n",
    "    features = {}\n",
    "    for word in document_words:\n",
    "        if word in word_features:\n",
    "            features[word] = features.get(word, 0) + 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def document_features3(document):\n",
    "    word_features3 = list(pos_words) + list(neg_words)\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features3:\n",
    "        features[word] = word in document_words\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter stopwords, punctuation marks, and numbers\n",
    "# 'stopwords_english': stopwords_english,\n",
    "# 'stopwords_domain': stopwords_domain,\n",
    "# 'punctuation': punctuation,\n",
    "# 'numbers': True,\n",
    "#\n",
    "# Do not filter stopwords, punctuation marks, or numbers\n",
    "# 'stopwords_english': [],\n",
    "# 'stopwords_domain': [],\n",
    "# 'punctuation': [],\n",
    "# 'numbers': False,\n",
    "\n",
    "options = {}\n",
    "\n",
    "#Option 1\n",
    "opt1 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': True,\n",
    "}\n",
    "options[1] = opt1\n",
    "\n",
    "#Option 2\n",
    "opt2 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': [],\n",
    "    'numbers': True,\n",
    "}\n",
    "options[2] = opt2\n",
    "\n",
    "#Option 3\n",
    "opt3 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': True,\n",
    "}\n",
    "options[3] = opt3\n",
    "\n",
    "#Option 4\n",
    "opt4 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': True,\n",
    "}\n",
    "options[4] = opt4\n",
    "\n",
    "#Option 5\n",
    "opt5 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': True,\n",
    "}\n",
    "options[5] = opt5\n",
    "\n",
    "#Option 6\n",
    "opt6 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': True,\n",
    "}\n",
    "options[6] = opt6\n",
    "\n",
    "#Option 7\n",
    "opt7 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': [],\n",
    "    'numbers': True,\n",
    "}\n",
    "options[7] = opt7\n",
    "\n",
    "#Option 8\n",
    "opt8 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': True,\n",
    "}\n",
    "options[8] = opt8\n",
    "\n",
    "#Option 9\n",
    "opt9 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': False,\n",
    "}\n",
    "options[9] = opt9\n",
    "\n",
    "#Option 10\n",
    "opt10 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[10] = opt10\n",
    "\n",
    "#Option 11\n",
    "opt11 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': False,\n",
    "}\n",
    "options[11] = opt11\n",
    "\n",
    "#Option 12\n",
    "opt12 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': False,\n",
    "}\n",
    "options[12] = opt12\n",
    "\n",
    "#Option 13\n",
    "opt13 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[13] = opt13\n",
    "\n",
    "#Option 14\n",
    "opt14 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': False,\n",
    "}\n",
    "options[14] = opt14\n",
    "\n",
    "#Option 15\n",
    "opt15 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[15] = opt15\n",
    "\n",
    "#Option 16\n",
    "opt16 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[16] = opt16\n",
    "\n",
    "#Option 17\n",
    "opt17 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': True,\n",
    "}\n",
    "options[17] = opt17\n",
    "\n",
    "#Option 18\n",
    "opt18 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': True,\n",
    "}\n",
    "options[18] = opt18\n",
    "\n",
    "#Option 19\n",
    "opt19 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': True,\n",
    "}\n",
    "options[19] = opt19\n",
    "\n",
    "#Option 20\n",
    "opt20 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': True,\n",
    "}\n",
    "options[20] = opt20\n",
    "\n",
    "#Option 21\n",
    "opt21 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': False,\n",
    "}\n",
    "options[21] = opt21\n",
    "\n",
    "#Option 22\n",
    "opt22 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[22] = opt22\n",
    "\n",
    "#Option 23\n",
    "opt23 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': False,\n",
    "}\n",
    "options[23] = opt23\n",
    "\n",
    "#Option 24\n",
    "opt24 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features1,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[24] = opt24\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "#Option 25\n",
    "opt25 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features2,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': True,\n",
    "}\n",
    "options[25] = opt25\n",
    "\n",
    "#Option 26\n",
    "opt26 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features3,\n",
    "    'stopwords_english': stopwords_english,\n",
    "    'stopwords_domain': stopwords_domain,\n",
    "    'punctuation': punctuation,\n",
    "    'numbers': True,\n",
    "}\n",
    "options[26] = opt26\n",
    "\n",
    "#Option 27\n",
    "opt27 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features2,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[27] = opt27\n",
    "\n",
    "#Option 28\n",
    "opt28 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': False,\n",
    "    'document_features': document_features3,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[28] = opt28\n",
    "\n",
    "#Option 29\n",
    "opt29 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features2,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[29] = opt29\n",
    "\n",
    "#Option 30\n",
    "opt30 = {\n",
    "    'length': 1000,\n",
    "    'reverse': False,\n",
    "    'stopwords_domain_in_features': True,\n",
    "    'document_features': document_features3,\n",
    "    'stopwords_english': [],\n",
    "    'stopwords_domain': [],\n",
    "    'punctuation': [],\n",
    "    'numbers': False,\n",
    "}\n",
    "options[30] = opt30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filt(x):\n",
    "    c1 = x not in options[opt]['stopwords_english']\n",
    "    c2 = x not in options[opt]['stopwords_domain']\n",
    "    c3 = x not in options[opt]['punctuation']\n",
    "    c4 = True if options[opt]['numbers'] else not x.isdigit()\n",
    "    \n",
    "    cs = [c1, c2, c3, c4]\n",
    "    return all(cs)\n",
    " \n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_words = filter(filt, tokens)\n",
    "    return filtered_words\n",
    "\n",
    "def print_option(opt):\n",
    "    d = dict(opt)\n",
    "    for k in d:\n",
    "        if (type(d[k]) == list or type(d[k]) == str) and len(d[k]) > 0:\n",
    "            d[k] = ['...']\n",
    "        elif hasattr(d[k], '__call__'):\n",
    "            d[k] = d[k].func_name\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "RUNNING THE MaxentClassifier WITH THE NEXT OPTIONS:\n",
      "\n",
      "Option 1\n",
      "{'reverse': False, 'stopwords_domain_in_features': False, 'punctuation': ['...'], 'length': 1000, 'numbers': True, 'document_features': 'document_features1', 'stopwords_domain': ['...'], 'stopwords_english': ['...']}\n",
      "majority\n",
      "\n",
      "iteration: 0\n",
      "\n",
      "----------------\n",
      "Total features:\n",
      "1000\n",
      "Top 10 features:\n",
      "[u'said', u'chief', u'mr.', u'like', u'would', u'director', u'one', u'year', u'also', u'president']\n",
      "----------------\n",
      "  ==> Training (100 iterations)"
     ]
    }
   ],
   "source": [
    "#%%prun -l4\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "\n",
    "best_option = None\n",
    "best_accuracy = 0\n",
    "best_index = 0\n",
    "d_accuracies = defaultdict(list)\n",
    "\n",
    "all_words = [w.lower() for d in original_documents for w in nltk.word_tokenize(d[0])]\n",
    "\n",
    "for i in range(10):\n",
    "    shuffle(original_documents)\n",
    "    for opt in options:\n",
    "        print('=======================================================')\n",
    "        print('RUNNING THE MaxentClassifier WITH THE NEXT OPTIONS:')\n",
    "        print('\\nOption {}'.format(opt))\n",
    "        print_option(options[opt])\n",
    "        print(score_calculate.func_name)\n",
    "        print('\\niteration: {}\\n'.format(i))\n",
    "        \n",
    "        documents = [(preprocess(d[0]), d[1]) for d in original_documents]\n",
    "        filtered_words = filter(filt, all_words)\n",
    "        freq_dist = nltk.FreqDist(filtered_words)\n",
    "        most_common_words = [word for word, freq in freq_dist.most_common()]\n",
    "        most_common_words = filter(filt, most_common_words)\n",
    "\n",
    "        if options[opt]['stopwords_domain_in_features']:\n",
    "            most_common_words = list(set(most_common_words).difference(search_terms))\n",
    "        if options[opt]['reverse']:\n",
    "            most_common_words.reverse()\n",
    "        \n",
    "        word_features = most_common_words[:options[opt]['length']]\n",
    "        print('----------------')\n",
    "        print('Total features:')\n",
    "        print(options[opt]['length'])\n",
    "        print('Top 10 features:')\n",
    "        print(word_features[:10])\n",
    "        print('----------------')\n",
    "\n",
    "        if options[opt]['document_features'] == document_features3:\n",
    "            pos_words = set(all_pos_words).intersection(word_features)\n",
    "            print('Total positive words:')\n",
    "            print(len(pos_words))\n",
    "            print('Top 10 positive words:')\n",
    "            print list(pos_words)[:10]\n",
    "\n",
    "            neg_words = set(all_neg_words).intersection(word_features)\n",
    "            print('Total positive words:')\n",
    "            print(len(neg_words))\n",
    "            print('Top 10 positive words:')\n",
    "            print list(neg_words)[:10]\n",
    "\n",
    "        featureset = [(options[opt]['document_features'](d[0]), d[1]) for d in documents]\n",
    "        size = int(len(featureset) * 0.9)\n",
    "        train_set = featureset[:size]\n",
    "        test_set = featureset[size:]\n",
    "\n",
    "        classifier = nltk.MaxentClassifier.train(train_set)\n",
    "        accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "        print('****************')\n",
    "        print('ACCURACY = {}'.format(accuracy))\n",
    "        print('****************')\n",
    "#         classifier.show_most_informative_features(10)\n",
    "        print('\\n\\n\\n\\n\\n')\n",
    "        d_accuracies[opt].append(accuracy)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_option = options[opt]\n",
    "            best_index = opt\n",
    "\n",
    "print('**************** BEST RESULT ****************')\n",
    "print('BEST OPTION: {}'.format(best_index))\n",
    "print(best_option)\n",
    "print('ACCURACY =', best_accuracy)\n",
    "print('*********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in options:\n",
    "    print('Option {}'.format(k))\n",
    "    print(np.array(d_accuracies[k]).mean())\n",
    "    print(np.array(d_accuracies[k]).std())\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cPickle as pickle\n",
    "\n",
    "# with open(\"sentiment/nltk_NaiveBayesClassifier_majority.pickle\", \"wb\") as nltk_file:\n",
    "#     pickle.dump(???, nltk_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
