{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sentence extractor for The New York Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from datetime import timedelta, date, datetime\n",
    "from dateutil import parser\n",
    "from time import sleep, time\n",
    "\n",
    "import requests\n",
    "from joblib import Parallel, delayed\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import BulkWriteError, DuplicateKeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('search2.log')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.getLogger().handlers = []\n",
    "logging.getLogger('requests.packages.urllib3').setLevel(logging.WARNING)\n",
    "logging.basicConfig(filename='search2.log', level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_log(*args, status=None):\n",
    "    record = '{} ==> {}'.format(args, status)\n",
    "    logging.info(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "client.drop_database('nytimes2')\n",
    "db = client.nytimes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_documents(docs, q):\n",
    "    try:\n",
    "        inserted = db.articles.insert_many(docs, ordered=False)\n",
    "        total_inserted = len(inserted.inserted_ids)\n",
    "        write_log(q, status='INSERTION OK {}'.format(total_inserted))\n",
    "    except BulkWriteError as e:\n",
    "        write_log(e, status='INSERTION EXCEPTION BULKWRITE')\n",
    "    except Exception as e:\n",
    "        write_log(e, status='INSERTION EXCEPTION OTHER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_terms(term_list):\n",
    "    search_terms = []\n",
    "    search_terms_aux = []\n",
    "    \n",
    "    for term in term_list:\n",
    "        if '-' in term or ' & ' in term or ' and ' in term:\n",
    "            if '-' in term:\n",
    "                search_terms_aux.append((term, term.lower()))\n",
    "                search_terms_aux.append((term, term.replace('-', '').lower()))\n",
    "                search_terms_aux.append((term, term.replace('-', ' ').lower()))\n",
    "            if ' & ' in term:\n",
    "                search_terms_aux.append((term, term.replace(' & ', ' ').lower()))\n",
    "            if ' and ' in term:\n",
    "                search_terms_aux.append((term, term.replace(' and ', ' ').lower()))\n",
    "        else:\n",
    "            search_terms_aux.append((term, term.lower()))\n",
    "    \n",
    "    for original, curated in search_terms_aux:\n",
    "        if curated.endswith('corporation'):\n",
    "            search_terms.append((original, curated[:-12]))\n",
    "        elif curated.endswith('company'):\n",
    "            search_terms.append((original, curated[:-8]))\n",
    "        elif curated.endswith('inc.'):\n",
    "            search_terms.append((original, curated[:-5]))\n",
    "        elif curated.endswith('inc'):\n",
    "            search_terms.append((original, curated[:-4]))\n",
    "        search_terms.append((original, curated))\n",
    "    \n",
    "    search_terms = map(lambda x: (x[0], '\"{}\"'.format(x[1])), search_terms)\n",
    "    return search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st_file = open('search_terms.txt')\n",
    "term_list = map(lambda x: x.strip(), st_file.readlines())\n",
    "search_terms = preprocess_terms(term_list)\n",
    "search_terms = [('entrepreneur', 'entrepreneur'), ('executive', 'executive')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##NYTimes API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One API key for each of the cores\n",
    "api_keys = [\n",
    "    \"3439a9084efa80c4f5fb1d290dfc1b44:11:70233981\", # my api key\n",
    "    \"a5c709f3168b829711241b243457e9d6:13:70235641\", # the other api key\n",
    "#     \"c7ba2eac72924572152e63f4516210d7:14:72380734\", # my second api key\n",
    "#     \"7e692d35c7bd20618395859a3c4cbef6:15:72380785\", # my third api key\n",
    "#     \"ba47374fd391c9bc5fd3ca51ff953a44:14:70229228\",\n",
    "#     \"4557e02788189abb3642a33bca7469ff:11:69136863\",\n",
    "#     \"2b3d39fd4c7836168a2a370c25ad6232:16:70235576\",\n",
    "#     \"87d7b22c0feec4f3112d80b71d0b500a:1:69642501\",\n",
    "#     \"d7655429355ab2df4621a10c01d04865:8:69135199\",\n",
    "#     \"1944df13b86dd83e4a8c4ea82e767975:2:65092848\",\n",
    "#     \"730e30f5220059551e666430644fbf87:11:69642501\", # developer inactive\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_multiple(n, m):\n",
    "    # 4, 17 ==> 20\n",
    "    rest = m % n\n",
    "    return m if rest == 0 else m + n - rest\n",
    "\n",
    "def chunks(l, n_chunks):\n",
    "    l = list(l)\n",
    "    size = len(l)\n",
    "    n = next_multiple(n_chunks, size) // n_chunks\n",
    "    for i in range(0, size, n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_terms_by_api_key = {}\n",
    "for t in zip(api_keys, chunks(search_terms, len(api_keys))):\n",
    "    search_terms_by_api_key[t[0]] = t[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def month_duration(d):\n",
    "    if d.month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        ndays = 31\n",
    "    elif d.month in [4, 6, 9, 11]:\n",
    "        ndays = 30\n",
    "    else: # d.month == 2\n",
    "        if d.year % 400 == 0 or d.year % 4 == 0 and d.year % 100 != 0: # lap-year\n",
    "            ndays = 29\n",
    "        else:\n",
    "            ndays = 28\n",
    "    return ndays\n",
    "\n",
    "def n_days(d, n_months):\n",
    "    ndays = 0\n",
    "    new_d = d\n",
    "    for _ in range(n_months):\n",
    "        m_duration = month_duration(d)\n",
    "        d += timedelta(m_duration)\n",
    "        ndays += m_duration\n",
    "    return ndays - 1\n",
    "\n",
    "def date_ranges(begin_date, end_date, n_months=1):\n",
    "    aux_date = begin_date\n",
    "    while aux_date < end_date:\n",
    "        ndays = n_days(aux_date, n_months)\n",
    "        yield (aux_date, min(aux_date + timedelta(ndays), end_date))\n",
    "        aux_date += timedelta(ndays + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LAST_REQUEST = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wait(f, *args, t=0):\n",
    "    global LAST_REQUEST\n",
    "    now = time()\n",
    "    elapsed_time = now - LAST_REQUEST\n",
    "    if elapsed_time < t:\n",
    "        sleep(t - elapsed_time)\n",
    "    LAST_REQUEST = time()\n",
    "    return f(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, term, begin_date, end_date, page, api_key):\n",
    "        self.term = term\n",
    "        self.begin_date = begin_date\n",
    "        self.end_date = end_date\n",
    "        self.page = page\n",
    "        self.api_key =api_key\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Q<{}, {}, {}, {}, {}>'.format(self.term, self.begin_date, self.end_date, self.page, self.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BEGIN_DATE = date(1999, 1, 1)\n",
    "# END_DATE = date(2014, 12, 31)\n",
    "BEGIN_DATE = date(2014, 1, 1)\n",
    "END_DATE = date(2014, 2, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(q):\n",
    "    base_url = 'http://api.nytimes.com/svc/search/v2/articlesearch.json'\n",
    "    payload = {'q': q.term, 'begin_date': q.begin_date, 'end_date': q.end_date, 'page': q.page, 'api-key': q.api_key}\n",
    "    fl = [\n",
    "        'web_url', 'snippet', 'lead_paragraph', 'abstract', 'source', 'headline',\n",
    "        'keywords', 'pub_date', 'document_type', 'section_name', '_id',\n",
    "    ]\n",
    "    payload.update({'sort': 'oldest', 'fq': 'source:(\"The New York Times\")', 'fl': ','.join(fl)})\n",
    "    response = requests.get(base_url, params=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_documents_by_page(q, original, total_results):\n",
    "    n_pages = math.ceil(total_results / 10)\n",
    "    for page in range(n_pages):\n",
    "        q.page = page\n",
    "        response = wait(search, q)\n",
    "        if response['status'] != 'OK':\n",
    "            write_log(q, status='SEARCH PAGE {}'.format(response['status']))\n",
    "        else:\n",
    "            docs = response['response']['docs']\n",
    "            for doc in docs:\n",
    "                doc.update({'q': q.__dict__, 'original': original})\n",
    "            insert_documents(docs, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_documents_by_date(q, original):\n",
    "    response = wait(search, q)\n",
    "    \n",
    "    if response['status'] != 'OK':\n",
    "        write_log(q, status='SEARCH DATERANGE {}'.format(response['status']))\n",
    "    else:\n",
    "        total_results = response['response']['meta']['hits']\n",
    "        write_log(q, status='SEARCH {} {}'.format(response['status'], total_results))\n",
    "            \n",
    "        if total_results <= 1010:\n",
    "            get_documents_by_page(q, original, total_results)\n",
    "        else:\n",
    "            bd = parser.parse(q.begin_date)\n",
    "            ed = parser.parse(q.end_date)\n",
    "            half = (ed - bd) // 2\n",
    "            \n",
    "            begin_date1 = q.begin_date\n",
    "            end_date1 = (bd + timedelta(half.days)).strftime(\"%Y%m%d\")\n",
    "            q1 = Query(q.term, begin_date1, end_date1, 0, q.api_key)\n",
    "            get_documents_by_date(q1, original)\n",
    "            \n",
    "            begin_date2 = (bd + timedelta(half.days + 1)).strftime(\"%Y%m%d\")\n",
    "            end_date2 = q.end_date\n",
    "            q2 = Query(q.term, begin_date2, end_date2, 0, q.api_key)\n",
    "            get_documents_by_date(q2, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_by_date_ranges(term, api_key):\n",
    "    for r in date_ranges(BEGIN_DATE, END_DATE, 1):\n",
    "        try:\n",
    "            begin_date = r[0].strftime(\"%Y%m%d\")\n",
    "            end_date = r[1].strftime(\"%Y%m%d\")\n",
    "            q = Query(term[1], begin_date, end_date, 0, api_key)\n",
    "            get_documents_by_date(q, term[0])\n",
    "        except Exception as e:\n",
    "            write_log(e, status='DOWNLOAD EXCEPTION DATERANGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_by_term(term, api_key):\n",
    "    begin_date = BEGIN_DATE.strftime(\"%Y%m%d\")\n",
    "    end_date = END_DATE.strftime(\"%Y%m%d\")\n",
    "    try:\n",
    "        q = Query(term[1], begin_date, end_date, 0, api_key)\n",
    "        response = wait(search, q)\n",
    "        \n",
    "        if response['status'] != 'OK':\n",
    "            write_log(q, status='SEARCH TERM {}'.format(response['status']))\n",
    "        else:\n",
    "            total_results = response['response']['meta']['hits']\n",
    "            write_log(q, status='SEARCH TERM {} {}'.format(response['status'], total_results))\n",
    "            \n",
    "            if total_results == 0:\n",
    "                write_log(q, status='SEARCH BY TERM 0')\n",
    "            elif total_results <= 1010:\n",
    "                get_documents_by_page(q, term[0], total_results)\n",
    "            else:\n",
    "                download_by_date_ranges(term, api_key)\n",
    "    except Exception as e:\n",
    "        write_log(e, status='DOWNLOAD EXCEPTION TERM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_by_key(search_terms, api_key):\n",
    "    for term in search_terms:\n",
    "        try:\n",
    "            download_by_term(term, api_key)\n",
    "        except Exception as e:\n",
    "            write_log(e, status='DOWNLOAD EXCEPTION TERM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def downloader(search_terms_by_api_key, api_keys):\n",
    "    # Version parallel\n",
    "    Parallel(n_jobs=2)(delayed(download_by_key)(search_terms_by_api_key[api_key], api_key) for api_key in api_keys)\n",
    "\n",
    "    # Version sequencial\n",
    "    for api_key in api_keys:\n",
    "        try:\n",
    "            download_by_key(search_terms_by_api_key[api_key], api_key)\n",
    "        except Exception as e:\n",
    "            write_log(e, status='DOWNLOAD EXCEPTION KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downloader(search_terms_by_api_key, api_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
