{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Meme Ivey report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Dataset\n",
    "The dataset is formed by 8996 sentences obtained by searching specific terms from XXX and retrieving the sentences that contained those terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. Sentence scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Students' scores\n",
    "The sentences have been evaluated by XXX students with values ranged from âˆ’2 (very negative) to +2 (very positive). Not every student has evaluated all the senteces but every sentence have been evaluated at least three times (by three different students).\n",
    "\n",
    "The final score per sentence is the average of its individual evaluations. Therefore, every sentence has a final score between -2 and +2. Finally, this score has been normalized to the range [-1, +1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####LIWC scores\n",
    "In order to estimate the soundness of LIWC at analyzing the sentiment of our dataset, we have run this software with the following options:\n",
    "- Metrics:\n",
    "    - posemo: % of words that express a positive emotion\n",
    "    - negemo: % of words that express a negative emotion\n",
    "- Segment delimiter:\n",
    "    - newline: the original file is splitted into individual lines, i. e., the analysis is performed sentence by sentence\n",
    "- Tokens:\n",
    "    - words: the words are the only type of token taken into account; numerals and punctuation marks are ignored\n",
    "\n",
    "Upon completing the analysis, every sentence has a value for posemo, between 0 and 100 (%), and another value for negemo, also between 0 and 100 (%). We have considered two options the calculate the final score per sentence:\n",
    "- Option 1) Subtraction:\n",
    "    - posemo - negemo\n",
    "- Option 2) Maximum:\n",
    "    - if posemo > negemo, then posemo\n",
    "    - if posemo < negemo, then -negemo\n",
    "    - if posemo = negemo, then 0\n",
    "In both cases, the final score for every sentence is between -100 and +100.\n",
    "\n",
    "In order to normalize, we have followed two different criteria:\n",
    "- Option a) Normalizing from the full range:\n",
    "    - [-100, +100] -> [-1, +1]\n",
    "- Option b) Normalizing from the maximum range observed. Let mpe be the maximum value for posemo, mne the maximum value for negemo, among all the sentences, and m the maximum value between mpe and mne; then:\n",
    "    - [-m, +m] -> [-1, +1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Comparison between the students' results and LIWC's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Histogram of sentences scored by students\n",
    "<div align=\"center\">\n",
    "    <figure>\n",
    "        <img src=\"histogram_students.png\"/>\n",
    "        <figcaption>Fig.1 Histogram of sentences scored by students</figcaption>\n",
    "    </figure>\n",
    "</div>\n",
    "- It follows a normal distribution slightly ... desplazada hacia la zona positiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Comparison to histograms of sentences scored by LIWC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <figure>\n",
    "        <img src=\"histogram_a_1.png\"/>\n",
    "        <figcaption>Fig.2 Comparison to histogram of sentences scored by LIWC, options a) full range 1) subtraction</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <figure>\n",
    "        <img src=\"histogram_a_2.png\"/>\n",
    "        <figcaption>Fig.3 Comparison to histogram of sentences scored by LIWC, options a) full range 2) maximum</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <figure>\n",
    "        <img src=\"histogram_b_1.png\"/>\n",
    "        <figcaption>Fig.4 Comparison to histogram of sentences scored by LIWC, options b) maximum range 1) subtraction</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <figure>\n",
    "        <img src=\"histogram_b_2.png\"/>\n",
    "        <figcaption>Fig.5 Comparison to histogram of sentences scored by LIWC, options b) maximum range 2) maximum</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###4. Accuracy\n",
    "Both the specific measure used and the range chosen do not affect the final polarity of a sentence. That is, in all cases, given a sentence, it got the same polarity for each of the four previous approaches. The accuracy of this result with respect to the polarity assigned by the students is:\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td>Total sentences</td><td>8996</td></tr>\n",
    "        <tr><td>Sentences evaluated with same polarity</td><td>3202</td></tr>\n",
    "        <tr><td>Sentences evaluated with different polarity</td><td>5794</td></tr>\n",
    "        <tr><td>LIWC accuracy</td><td>35.59%</td></tr>\n",
    "        <caption>LIWC accuracy</caption>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###5. Conclusions\n",
    "The results show that, on one hand, in the best cases (Fig. 4 and 5), LIWC does not classify correctly most of the sentences and it assigns them a neutral value (between 0.0 and 0.1). On the other hand, the accuracy of LIWC is 35.59% (the minimum value admissible for any classificator is 70%). Therefore, the conclusion is **it is necessary to create a more suitable classifier for this case study**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###6. Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6068f4b5ff32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
