{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Data\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bossa/tasks_export.json  bossa/tasks_runs_export.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls bossa/*json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOSSA Results\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing `results_bossa.json` to get a *dictionary* with keys the task ids, and values in as the average value of the scores. To do that, we first convert scores from categorical (`neg`, `neu`, `pos`) to a numeric scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>task_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11203</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>52775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_id   seconds  task_id score\n",
       "50      11203  0.000025    52775     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bossa_results = pd.read_json(\"bossa/tasks_runs_export.json\")\n",
    "bossa_results.rename(columns={\"created\": \"start_time\", \"id\": \"result_id\", \"info\": \"score\"}, inplace=True)\n",
    "bossa_results[['start_time']]= bossa_results[['start_time']].apply(pd.to_datetime, dayfirst=True)\n",
    "bossa_results[['finish_time']]= bossa_results[['finish_time']].apply(pd.to_datetime, dayfirst=True)\n",
    "bossa_results['score'] = pd.Categorical(bossa_results['score'], categories=['vneg', 'neg', 'neu', 'pos', 'vpos'])\n",
    "bossa_results['score'].cat.rename_categories([-2, -1, 0, 1, 2], inplace=True)\n",
    "# Normalize everything to -1, 0, 1\n",
    "# bossa_results['score'] = bossa_results['score'].astype(float).apply(lambda x: -1 if x < 0 else 1 if x > 0 else 0)\n",
    "bossa_results[\"seconds\"] = (bossa_results[\"finish_time\"] - bossa_results[\"start_time\"]).astype('timedelta64[us]') / 1e6\n",
    "bossa_results = bossa_results[[\"result_id\", \"seconds\", \"task_id\", \"score\"]]\n",
    "bossa_results.ix[[50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information about the sentence comes in a dictionary inside the cells of the serie `info`, so we expand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>52851</td>\n",
       "      <td>{u'search_words': u'founder', u'appears_in_sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_id                                               info\n",
       "50    52851  {u'search_words': u'founder', u'appears_in_sen..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bossa_tasks = pd.read_json(\"bossa/tasks_export.json\")\n",
    "bossa_tasks[['created']]= bossa_tasks[['created']].apply(pd.to_datetime, dayfirst=True)\n",
    "bossa_tasks.rename(columns={'id': 'task_id'}, inplace=True)\n",
    "bossa_tasks = bossa_tasks[['task_id', 'info']]\n",
    "bossa_tasks.ix[[50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we merge the `DataFrame` with the scores with the one containing the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>task_id</th>\n",
       "      <th>score</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11195</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>52776</td>\n",
       "      <td>2</td>\n",
       "      <td>{u'search_words': u'executive', u'appears_in_s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_id   seconds  task_id  score  \\\n",
       "50      11195  0.000021    52776      2   \n",
       "\n",
       "                                                 info  \n",
       "50  {u'search_words': u'executive', u'appears_in_s...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bossa_tasks_scores = pd.merge(bossa_results, bossa_tasks, on='task_id')\n",
    "bossa_tasks_scores.ix[[50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now expand the column `info` into as many new columns as keys has the dictionary `info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'search_words',\n",
       " u'appears_in_sentence',\n",
       " u'url',\n",
       " u'media',\n",
       " u'appears_in_noun_phrases',\n",
       " u'noun_phrases',\n",
       " u'sentence_id',\n",
       " u'text',\n",
       " u'sentence',\n",
       " u'pub_date',\n",
       " u'is_company']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bossa_tasks_scores.ix[50].info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>task_id</th>\n",
       "      <th>score</th>\n",
       "      <th>search_words</th>\n",
       "      <th>appears_in_sentence</th>\n",
       "      <th>url</th>\n",
       "      <th>media</th>\n",
       "      <th>appears_in_noun_phrases</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>is_company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11195</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>52776</td>\n",
       "      <td>2</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>http://dealbook.nytimes.com/2013/05/17/a-toeho...</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0</td>\n",
       "      <td>[chinese investors, overseas companies, politi...</td>\n",
       "      <td>14</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>2013-05-17T11:47:51Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>11205</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>52776</td>\n",
       "      <td>-1</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>http://dealbook.nytimes.com/2013/05/17/a-toeho...</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0</td>\n",
       "      <td>[chinese investors, overseas companies, politi...</td>\n",
       "      <td>14</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>2013-05-17T11:47:51Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>11207</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>52776</td>\n",
       "      <td>1</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>http://dealbook.nytimes.com/2013/05/17/a-toeho...</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0</td>\n",
       "      <td>[chinese investors, overseas companies, politi...</td>\n",
       "      <td>14</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>2013-05-17T11:47:51Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>11209</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>52776</td>\n",
       "      <td>-2</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>http://dealbook.nytimes.com/2013/05/17/a-toeho...</td>\n",
       "      <td>nyt</td>\n",
       "      <td>0</td>\n",
       "      <td>[chinese investors, overseas companies, politi...</td>\n",
       "      <td>14</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>Chinese investors are increasingly opting to b...</td>\n",
       "      <td>2013-05-17T11:47:51Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_id   seconds  task_id  score search_words appears_in_sentence  \\\n",
       "50      11195  0.000021    52776      2    executive                   0   \n",
       "51      11205  0.000018    52776     -1    executive                   0   \n",
       "52      11207  0.000017    52776      1    executive                   0   \n",
       "53      11209  0.000017    52776     -2    executive                   0   \n",
       "\n",
       "                                                  url media  \\\n",
       "50  http://dealbook.nytimes.com/2013/05/17/a-toeho...   nyt   \n",
       "51  http://dealbook.nytimes.com/2013/05/17/a-toeho...   nyt   \n",
       "52  http://dealbook.nytimes.com/2013/05/17/a-toeho...   nyt   \n",
       "53  http://dealbook.nytimes.com/2013/05/17/a-toeho...   nyt   \n",
       "\n",
       "   appears_in_noun_phrases                                       noun_phrases  \\\n",
       "50                       0  [chinese investors, overseas companies, politi...   \n",
       "51                       0  [chinese investors, overseas companies, politi...   \n",
       "52                       0  [chinese investors, overseas companies, politi...   \n",
       "53                       0  [chinese investors, overseas companies, politi...   \n",
       "\n",
       "   sentence_id                                               text  \\\n",
       "50          14  Chinese investors are increasingly opting to b...   \n",
       "51          14  Chinese investors are increasingly opting to b...   \n",
       "52          14  Chinese investors are increasingly opting to b...   \n",
       "53          14  Chinese investors are increasingly opting to b...   \n",
       "\n",
       "                                             sentence              pub_date  \\\n",
       "50  Chinese investors are increasingly opting to b...  2013-05-17T11:47:51Z   \n",
       "51  Chinese investors are increasingly opting to b...  2013-05-17T11:47:51Z   \n",
       "52  Chinese investors are increasingly opting to b...  2013-05-17T11:47:51Z   \n",
       "53  Chinese investors are increasingly opting to b...  2013-05-17T11:47:51Z   \n",
       "\n",
       "   is_company  \n",
       "50          0  \n",
       "51          0  \n",
       "52          0  \n",
       "53          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def json_to_series(info):\n",
    "    keys, values = zip(*info.iteritems())\n",
    "    return pd.Series(values, index=keys)\n",
    "\n",
    "bossa_info = bossa_tasks_scores[\"info\"].apply(json_to_series)\n",
    "bossa_info.reset_index()\n",
    "bossa = pd.concat([bossa_tasks_scores, bossa_info], axis=1)\n",
    "bossa.pop(\"info\")\n",
    "# bossa['id'] = bossa['id'].astype(float)\n",
    "bossa.ix[50:53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now aggregate calculating the average per `sentence_id` using a group by. In the process, we lose the source of the data, that's why we first have to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bossa.to_csv(\"sentiment/scores_ungrouped.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we aggregate and create a new `DataFrame` for the different sentences and their score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score    8996\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'We must hope after so much prevarication that this time Google's proposals represent a genuine attempt to address the concerns identified,' said David Wood, the legal counsel for Icomp, an industry group backed by Microsoft and a number of other companies.</th>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'We must push our leaders to step up and commit to action,' said Hugh Evans, the founder and chief executive of the charity.</th>\n",
       "      <td>-0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'We need them to tell the story of how we are making decisions and putting the organization together,' said George Postolos, the Astros' president and chief executive, who added that the team would not want a broadcaster who was uncomfortable explaining the front office's strategy.</th>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                               score\n",
       "sentence                                                                                                                                                                                                                                                                                            \n",
       "'We must hope after so much prevarication that this time Google's proposals represent a genuine attempt to address the concerns identified,' said David Wood, the legal counsel for Icomp, an industry group backed by Microsoft and a number of other companies.                          -0.333333\n",
       "'We must push our leaders to step up and commit to action,' said Hugh Evans, the founder and chief executive of the charity.                                                                                                                                                               -0.285714\n",
       "'We need them to tell the story of how we are making decisions and putting the organization together,' said George Postolos, the Astros' president and chief executive, who added that the team would not want a broadcaster who was uncomfortable explaining the front office's strategy. -0.666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = bossa.groupby(['sentence'])[['score']].aggregate(np.average)\n",
    "sentences.to_csv(\"sentiment/scores.csv\", encoding=\"utf8\")\n",
    "print sentences.count()\n",
    "sentences[1001:1004]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Classifier\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the tranining and testing sets (data and labels) from a randomized version of the set of assessed sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    8996\n",
       "score       8996\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.reset_index().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could consider 3 classes, but it toruns out that using binary classficication seems to produce better results. Still, try multi-classs classifiers is something worth trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos 2939 4281 755\n",
      "neg 2939 2498 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/.virtualenvs/knowledge/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "raw_scores = sentences.reset_index()\n",
    "scores = raw_scores\n",
    "scores = scores[scores.score!=0]  # We ignore the neutral sentences\n",
    "scores['sentiment'] = scores['score'].apply(lambda s: 'pos' if s > 0 else 'neg')\n",
    "percentage = 0.85  #  percentage for training, rest for for testing\n",
    "# We split to have enough representativenesss for both positive and negative sentiments\n",
    "sent_min = min(\n",
    "    scores[scores.sentiment=='pos'].sentiment.count(),\n",
    "    scores[scores.sentiment=='neg'].sentiment.count(),\n",
    ")\n",
    "scores = scores[[\"sentence\", \"sentiment\"]]\n",
    "train_data = np.array([])\n",
    "train_labels = np.array([])\n",
    "test_data = np.array([])\n",
    "test_labels = np.array([])\n",
    "for sent in ('pos', 'neg'):\n",
    "    sent_scores = scores[scores['sentiment']==sent]\n",
    "    sent_scores = sent_scores.reindex(np.random.permutation(sent_scores.index))\n",
    "    sent_sentences_count = int(sent_scores['sentence'].count())\n",
    "    sent_train = sent_scores[[\"sentence\", \"sentiment\"]][:int(sent_sentences_count * percentage)]\n",
    "    sent_test = sent_scores[[\"sentence\", \"sentiment\"]][int(sent_sentences_count * percentage) + 1:]\n",
    "    print sent, sent_min, sent_train.sentiment.count(), sent_test.sentiment.count()\n",
    "    train_data = np.append(train_data, sent_train[\"sentence\"])\n",
    "    train_labels = np.append(train_labels, sent_train[\"sentiment\"])\n",
    "    test_data = np.append(test_data, sent_test[\"sentence\"])\n",
    "    test_labels = np.append(test_labels, sent_test[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    " \n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_words = filter(lambda t: t not in stopwords.words('english'), tokens)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eight', \"o'clock\", 'thursday', 'morning', 'arthur', \"n't\", 'feel', 'good', '.', 'french-fries']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good. French-Fries\"\n",
    "print preprocess(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "document_df = scores[['sentence', 'sentiment']]\n",
    "document_df = document_df.reindex(np.random.permutation(document_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>As giants like Amazon.com move into the online...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\"One reason why Lloyds shares have appreciated...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>It was founded by Vernon Hill, an entrepreneur...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>'We are not in a rush in taking decisions,' sa...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>Samsung, which makes smartphones as well as th...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence sentiment\n",
       "2179  As giants like Amazon.com move into the online...       pos\n",
       "41    \"One reason why Lloyds shares have appreciated...       pos\n",
       "4605  It was founded by Vernon Hill, an entrepreneur...       neg\n",
       "950   'We are not in a rush in taking decisions,' sa...       pos\n",
       "6450  Samsung, which makes smartphones as well as th...       pos"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [(r[1]['sentence'], r[1]['sentiment']) for r in document_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'As giants like Amazon.com move into the online grocery business, an investment firm is betting that a technology company can help traditional retailers fight back.',\n",
       "  'pos'),\n",
       " (u'\"One reason why Lloyds shares have appreciated so much is that there is no other real pure-play UK bank to buy at a time when the British economy is bouncing back,\" says one leading asset manager.',\n",
       "  'pos'),\n",
       " (u'It was founded by Vernon Hill, an entrepreneur who pioneered his customer-friendly approach to branches at Commerce Bancorp in the US.',\n",
       "  'neg'),\n",
       " (u\"'We are not in a rush in taking decisions,' said Hanan Ashrawi, a member of the executive committee.\",\n",
       "  'pos'),\n",
       " (u\"Samsung, which makes smartphones as well as the chips that go into many other manufacturers' devices, rose 760 percent.\",\n",
       "  'pos')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = [w.lower() for d in documents for w in nltk.word_tokenize(d[0])]\n",
    "freq_dist = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u',', u'.', u\"'s\", u\"'\", u'executive', u'said', u'chief', u'apple', u'manager', u'company']\n"
     ]
    }
   ],
   "source": [
    "most_common_words = [word for word, freq in freq_dist.most_common()]\n",
    "most_common_words = filter(lambda t: t not in stopwords.words('english'), most_common_words)\n",
    "word_features = most_common_words[:1000]\n",
    "print word_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):      \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['%s' % word] = word in document_words\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureset = [(document_features(d[0]), d[1]) for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = featureset[100:]\n",
    "test_set = featureset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
