{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sentence extractor for The New York Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta, date, datetime\n",
    "from dateutil import parser\n",
    "from time import sleep, time\n",
    "\n",
    "import requests\n",
    "import yaml\n",
    "from joblib import Parallel, delayed\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import BulkWriteError, DuplicateKeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('search4.log')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.getLogger().handlers = []\n",
    "logging.getLogger('requests.packages.urllib3').setLevel(logging.WARNING)\n",
    "logging.basicConfig(filename='search4.log', level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_log(*args, status=None):\n",
    "    record = '{} ==> {}'.format(args, status)\n",
    "    logging.info(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "client.drop_database('nytimes4')\n",
    "db = client.nytimes4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_document(_id, new_q_info):\n",
    "    doc = db.articles.find_one({'_id': _id})\n",
    "    new_orig_term = list(new_q_info.keys())[0]\n",
    "    if new_orig_term in doc['q_info']:\n",
    "        doc['q_info'][new_orig_term].extend(new_q_info[new_orig_term])\n",
    "    else:\n",
    "        doc['q_info'].update(new_q_info)\n",
    "    db.articles.update({'_id': _id}, {'$set': {'q_info': doc['q_info']}})\n",
    "\n",
    "def insert_documents(docs, q):\n",
    "    try:\n",
    "        inserted = db.articles.insert_many(docs, ordered=False)\n",
    "        total_inserted = len(inserted.inserted_ids)\n",
    "        write_log(q, status='INSERTION OK {}'.format(total_inserted))\n",
    "    except BulkWriteError as e:\n",
    "        n_updated = 0\n",
    "        for err in e.details['writeErrors']:\n",
    "            if err['code'] == 11000:\n",
    "                try:\n",
    "                    _id = err['op']['_id']\n",
    "                    new_q_info = err['op']['q_info']\n",
    "                    update_document(_id, new_q_info)\n",
    "                    n_updated += 1\n",
    "                except Exception as ex:\n",
    "                    write_log(q, status='UPDATE EXCEPTION {} - {}'.format(err['errmsg'], ex))\n",
    "        write_log(q, status='INSERTION OK {}'.format(e.details['nInserted']))\n",
    "        write_log(q, status='UPDATE OK {}'.format(n_updated))\n",
    "    except Exception as e:\n",
    "        write_log(q, status='INSERTION EXCEPTION {}'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def preprocess_term(term):\n",
    "#     terms = []\n",
    "    \n",
    "#     curated_term = term.lower()\n",
    "#     curated_term = curated_term.replace(' & ', ' ')\n",
    "#     curated_term = curated_term.replace(' and ', ' ')\n",
    "#     terms.append(curated_term)\n",
    "#     if '-' in curated_term:\n",
    "#         terms.append(curated_term.replace('-', ''))\n",
    "# #         terms.append(curated_term.replace('-', ' ')) # same result\n",
    "\n",
    "#     for term in terms:\n",
    "#         if term.endswith('corporation'):\n",
    "#             terms.append(term[:-12])\n",
    "#         elif term.endswith('corp'):\n",
    "#             terms.append(term[:-5])\n",
    "#         elif term.endswith('company'):\n",
    "#             terms.append(term[:-8])\n",
    "#         elif term.endswith('inc.'):\n",
    "#             terms.append(term[:-5])\n",
    "#         elif term.endswith('inc'):\n",
    "#             terms.append(term[:-4])\n",
    "#         elif term.endswith('.com'):\n",
    "#             terms.append(term[:-4])\n",
    "    \n",
    "# #     terms = list(map(lambda x: '\"{}\"'.format(x), terms))\n",
    "#     return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# term_dict = {}\n",
    "# for i in range(1, 4):\n",
    "#     term_dict[i] = {}\n",
    "#     st_file = open('search_terms_{}.txt'.format(i))\n",
    "#     term_list = map(lambda x: x.strip(), st_file.readlines())\n",
    "#     for term in term_list:\n",
    "#         term_dict[i][term] = preprocess_term(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('search_terms.yml', 'w') as search_term_file:\n",
    "#     search_term_file.write(yaml.dump(term_dict, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('search_terms_4.yml') as search_term_file:\n",
    "    term_yaml = yaml.load(search_term_file.read())\n",
    "    #\n",
    "    for key in term_yaml:\n",
    "        d = term_yaml[key]\n",
    "        for k in d:\n",
    "            d[k] = list(map(lambda x: '\"{}\"'.format(x), d[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##NYTimes API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One API key for each of the cores\n",
    "api_keys = [\n",
    "#     \"3439a9084efa80c4f5fb1d290dfc1b44:11:70233981\", # my api key\n",
    "#     \"a5c709f3168b829711241b243457e9d6:13:70235641\", # the other api key\n",
    "    \"c7ba2eac72924572152e63f4516210d7:14:72380734\", # my second api key\n",
    "    \"7e692d35c7bd20618395859a3c4cbef6:15:72380785\", # my third api key\n",
    "    \"ba47374fd391c9bc5fd3ca51ff953a44:14:70229228\",\n",
    "#     \"4557e02788189abb3642a33bca7469ff:11:69136863\",\n",
    "#     \"2b3d39fd4c7836168a2a370c25ad6232:16:70235576\",\n",
    "#     \"87d7b22c0feec4f3112d80b71d0b500a:1:69642501\",\n",
    "#     \"d7655429355ab2df4621a10c01d04865:8:69135199\",\n",
    "#     \"1944df13b86dd83e4a8c4ea82e767975:2:65092848\",\n",
    "#     \"730e30f5220059551e666430644fbf87:11:69642501\", # developer inactive\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_multiple(n, m):\n",
    "    # 4, 17 ==> 20\n",
    "    rest = m % n\n",
    "    return m if rest == 0 else m + n - rest\n",
    "\n",
    "def chunks(l, n_chunks):\n",
    "    l = list(l)\n",
    "    size = len(l)\n",
    "    n = next_multiple(n_chunks, size) // n_chunks\n",
    "    for i in range(0, size, n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [(search_term, original_term, term_type)]\n",
    "search_terms = [(t, k2, k1)\n",
    "                   for k1 in term_yaml\n",
    "                       for k2 in term_yaml[k1]\n",
    "                           for t in term_yaml[k1][k2]\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # TEST\n",
    "\n",
    "# api_keys = [\n",
    "#     \"3439a9084efa80c4f5fb1d290dfc1b44:11:70233981\", # my api key\n",
    "#     \"a5c709f3168b829711241b243457e9d6:13:70235641\", # the other api key\n",
    "# ]\n",
    "\n",
    "# search_terms = [\n",
    "#     ('\"entrepreneur\"', 'entrepreneur', 1),\n",
    "#     ('\"executive\"', 'executive', 1),\n",
    "#     ('\"google\"', 'google', 2),\n",
    "#     ('\"amazon\"', 'amazon.com', 2),\n",
    "#     ('\"amazon.com\"', 'amazon.com', 3),\n",
    "#     ('\"ebay\"', 'e-bay', 3),\n",
    "# #     ('\"facebook\"', 'facebook', 3),\n",
    "# ]\n",
    "\n",
    "# BEGIN_DATE = date(2014, 1, 1)\n",
    "# END_DATE = date(2014, 2, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"desire2learn\"', 'desire2learn', 2),\n",
       " ('\"shopify\"', 'shopify', 3),\n",
       " ('\"slack.com\"', 'slack', 3),\n",
       " ('\"slackhq\"', 'slack', 3)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_terms_by_api_key = defaultdict(list)\n",
    "for i in range(2, 4):\n",
    "    search_terms_i = list(filter(lambda x: x[2] == i, search_terms))\n",
    "    for t in zip(api_keys, chunks(search_terms_i, len(api_keys))):\n",
    "        search_terms_by_api_key[t[0]].extend(t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def month_duration(d):\n",
    "    if d.month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        ndays = 31\n",
    "    elif d.month in [4, 6, 9, 11]:\n",
    "        ndays = 30\n",
    "    else: # d.month == 2\n",
    "        if d.year % 400 == 0 or d.year % 4 == 0 and d.year % 100 != 0: # lap-year\n",
    "            ndays = 29\n",
    "        else:\n",
    "            ndays = 28\n",
    "    return ndays\n",
    "\n",
    "def n_days(d, n_months):\n",
    "    ndays = 0\n",
    "    new_d = d\n",
    "    for _ in range(n_months):\n",
    "        m_duration = month_duration(d)\n",
    "        d += timedelta(m_duration)\n",
    "        ndays += m_duration\n",
    "    return ndays - 1\n",
    "\n",
    "def date_ranges(begin_date, end_date, n_months=1):\n",
    "    aux_date = begin_date\n",
    "    while aux_date < end_date:\n",
    "        ndays = n_days(aux_date, n_months)\n",
    "        yield (aux_date, min(aux_date + timedelta(ndays), end_date))\n",
    "        aux_date += timedelta(ndays + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LAST_REQUEST = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wait(f, *args, t=9):\n",
    "    global LAST_REQUEST\n",
    "    now = time()\n",
    "    elapsed_time = now - LAST_REQUEST\n",
    "    if elapsed_time < t:\n",
    "        sleep(t - elapsed_time)\n",
    "    LAST_REQUEST = time()\n",
    "    return f(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, term, begin_date, end_date, page, api_key):\n",
    "        self.term = term\n",
    "        self.begin_date = begin_date\n",
    "        self.end_date = end_date\n",
    "        self.page = page\n",
    "        self.api_key =api_key\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Q<{}, {}, {}, {}, {}>'.format(self.term, self.begin_date, self.end_date, self.page, self.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEGIN_DATE = date(1999, 1, 1)\n",
    "END_DATE = date(2014, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(q):\n",
    "    try:\n",
    "        base_url = 'http://api.nytimes.com/svc/search/v2/articlesearch.json'\n",
    "        payload = {'q': q.term, 'begin_date': q.begin_date, 'end_date': q.end_date, 'page': q.page, 'api-key': q.api_key}\n",
    "        fl = [\n",
    "            'web_url', 'snippet', 'lead_paragraph', 'abstract', 'source', 'headline',\n",
    "            'keywords', 'pub_date', 'document_type', 'section_name', '_id',\n",
    "        ]\n",
    "        payload.update({'sort': 'oldest', 'fq': 'source:(\"The New York Times\")', 'fl': ','.join(fl), 'hl': 'true'})\n",
    "        r = requests.get(base_url, params=payload)\n",
    "        response = r.json()\n",
    "        \n",
    "        if response['status'] == 'OK':\n",
    "            write_log(q, status='SEARCH OK {}'.format(response['response']['meta']['hits']))\n",
    "        elif response['status'] == 'ERROR':\n",
    "            write_log(q, status='SEARCH ERROR {}'.format(response['errors']))\n",
    "        else:\n",
    "            write_log(q, status='SEARCH {}'.format(response['status']))\n",
    "    except ValueError as e:\n",
    "        if str(e) == 'Expecting value: line 1 column 1 (char 0)':\n",
    "            write_log(q, status='SEARCH ERROR api-key')\n",
    "        else:\n",
    "            write_log(q, status='SEARCH EXCEPTION {}'.format(e))\n",
    "        response = {'status': 'ERROR'}\n",
    "    except Exception as e:\n",
    "        write_log(q, status='SEARCH EXCEPTION {}'.format(e))\n",
    "        response = {'status': 'ERROR'}\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_documents_by_page(q, term, total_results):\n",
    "    n_pages = math.ceil(total_results / 10)\n",
    "    for page in range(n_pages):\n",
    "        q.page = page\n",
    "        response = wait(search, q)\n",
    "        \n",
    "        if response['status'] == 'OK':\n",
    "            docs = response['response']['docs']\n",
    "            for doc in docs:\n",
    "                snippet = doc['snippet']\n",
    "                orig_term = term[1].replace('.', '_')\n",
    "                doc.update({'q_info': {orig_term: [{'q': q.__dict__, 'term_category': term[2], 'snippet': snippet}]}})\n",
    "                del(doc['snippet'])\n",
    "            insert_documents(docs, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_documents_by_query(q, term):\n",
    "    response = wait(search, q)\n",
    "    \n",
    "    if response['status'] == 'OK':\n",
    "        total_results = response['response']['meta']['hits']\n",
    "        if total_results <= 1010:\n",
    "            get_documents_by_page(q, term, total_results)\n",
    "        else:\n",
    "            bd = parser.parse(q.begin_date)\n",
    "            ed = parser.parse(q.end_date)\n",
    "            half = (ed - bd) // 2\n",
    "            \n",
    "            begin_date1 = q.begin_date\n",
    "            end_date1 = (bd + timedelta(half.days)).strftime(\"%Y%m%d\")\n",
    "            q1 = Query(q.term, begin_date1, end_date1, 0, q.api_key)\n",
    "            get_documents_by_query(q1, term)\n",
    "            \n",
    "            begin_date2 = (bd + timedelta(half.days + 1)).strftime(\"%Y%m%d\")\n",
    "            end_date2 = q.end_date\n",
    "            q2 = Query(q.term, begin_date2, end_date2, 0, q.api_key)\n",
    "            get_documents_by_query(q2, term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_by_date_ranges(term, api_key):\n",
    "    for r in date_ranges(BEGIN_DATE, END_DATE, 1):\n",
    "        begin_date = r[0].strftime(\"%Y%m%d\")\n",
    "        end_date = r[1].strftime(\"%Y%m%d\")\n",
    "        q = Query(term[0], begin_date, end_date, 0, api_key)\n",
    "        get_documents_by_query(q, term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_by_term(term, api_key):\n",
    "    begin_date = BEGIN_DATE.strftime(\"%Y%m%d\")\n",
    "    end_date = END_DATE.strftime(\"%Y%m%d\")\n",
    "    q = Query(term[0], begin_date, end_date, 0, api_key)\n",
    "    response = wait(search, q)\n",
    "    \n",
    "    if response['status'] == 'OK':\n",
    "        total_results = response['response']['meta']['hits']\n",
    "        if total_results <= 1010:\n",
    "            get_documents_by_page(q, term, total_results)\n",
    "        else:\n",
    "            download_by_date_ranges(term, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_by_key(terms, api_key):\n",
    "    for term in terms:\n",
    "        try:\n",
    "            download_by_term(term, api_key)\n",
    "        except Exception as e:\n",
    "            write_log(e, status='DOWNLOAD EXCEPTION {} {}'.format(term, api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def downloader(search_terms_by_api_key, api_keys):\n",
    "    # Version parallel\n",
    "    Parallel(n_jobs=3)(delayed(download_by_key)(search_terms_by_api_key[api_key], api_key) for api_key in api_keys)\n",
    "\n",
    "    # Version sequencial\n",
    "#     for api_key in api_keys:\n",
    "#         download_by_key(search_terms_by_api_key[api_key], api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "downloader(search_terms_by_api_key, api_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for d in db.articles.find():\n",
    "#     if len(d['q_info']) > 1:\n",
    "#         k = list(d['q_info'].keys())[0]\n",
    "#         if len(d['q_info'][k]) > 1:\n",
    "#             print(d['_id'])\n",
    "#             print(d['q_info'])\n",
    "#             break\n",
    "\n",
    "# 52c8a3eb38f0d862ec32236f\n",
    "# {\n",
    "# 'amazon_com': [{\n",
    "#     'q': {'page': 0, 'end_date': '20140228', 'term': '\"amazon.com\"', 'begin_date': '20140101', 'api_key': '3439a9084efa80c4f5fb1d290dfc1b44:11:70233981'},\n",
    "#     'term_category': 3,\n",
    "#     'snippet': 'Jeff Bezos, vacationing in the Galapagos Islands this week, felt some serious pain. And it wasn’t just because UPS had failed to make all of Amazon’s shipments by Christmas.'\n",
    "#     }, {\n",
    "#     'q': {'page': 0, 'begin_date': '20140101', 'end_date': '20140228', 'term': '\"amazon\"', 'api_key': 'a5c709f3168b829711241b243457e9d6:13:70235641'},\n",
    "#     'term_category': 2,\n",
    "#     'snippet': 'The Ecuadorean Navy offered Jeff Bezos same-day shipping on an <strong>Amazon</strong> Prime package: Mr. Bezos himself. Amazon’s chief executive suffered a kidney stone attack visiting the Galapagos Islands this week, according to the local'\n",
    "#     }],\n",
    "# 'executive': [{\n",
    "#     'q': {'page': 10, 'end_date': '20140116', 'term': '\"executive\"', 'begin_date': '20140101', 'api_key': 'a5c709f3168b829711241b243457e9d6:13:70235641'},\n",
    "#     'term_category': 1,\n",
    "#     'snippet': 'The Ecuadorean Navy offered Jeff Bezos same-day shipping on an Amazon Prime package: Mr. Bezos himself. Amazon’s chief <strong>executive</strong> suffered a kidney stone attack visiting the Galapagos Islands this week, according to the local'\n",
    "#     }]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# db.articles.find_one({'_id':'52c8a3eb38f0d862ec32236f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.articles.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document_type': 'article', 'keywords': [{'value': 'Computers and the Internet', 'rank': '1', 'name': 'subject', 'is_major': 'N'}, {'value': 'Entrepreneurship', 'rank': '2', 'name': 'subject', 'is_major': 'N'}, {'value': 'Blackboard Incorporated', 'rank': '3', 'name': 'organizations', 'is_major': 'N'}], 'lead_paragraph': 'A start-up’s strategy resembles a diplomatic dance more than a hard-charging coup d’état.', '_id': '54ae7b0138f0d817e02e7cd2', 'headline': {'main': 'Business Revolutionaries Learn Diplomacy’s Value', 'content_kicker': 'Under New Management', 'kicker': 'Under New Management', 'print_headline': 'Business Revolutionaries Learn Diplomacy’s Value'}, 'q_info': {'desire2learn': [{'snippet': 'to zero.” Even the company’s name sends a reassuring message. Most of its current rivals — companies like eCollege.com, <strong>Desire2Learn</strong>, and Jenzabar — have identities that underscore their roots in the Internet era. Not so Mr.', 'q': {'begin_date': '19990101', 'page': 0, 'term': '\"desire2learn\"', 'api_key': 'c7ba2eac72924572152e63f4516210d7:14:72380734', 'end_date': '20141231'}, 'term_category': 2}]}, 'web_url': 'http://www.nytimes.com/2006/07/16/business/yourmoney/16mgmt.html', 'abstract': None, 'section_name': 'Business Day', 'source': 'The New York Times', 'pub_date': '2006-07-16T00:00:00Z'}\n"
     ]
    }
   ],
   "source": [
    "for d in db.articles.find()[:1]:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '54ae7b0138f0d817e02e7cd2',\n",
       " 'abstract': None,\n",
       " 'document_type': 'article',\n",
       " 'headline': {'content_kicker': 'Under New Management',\n",
       "  'kicker': 'Under New Management',\n",
       "  'main': 'Business Revolutionaries Learn Diplomacy’s Value',\n",
       "  'print_headline': 'Business Revolutionaries Learn Diplomacy’s Value'},\n",
       " 'keywords': [{'is_major': 'N',\n",
       "   'name': 'subject',\n",
       "   'rank': '1',\n",
       "   'value': 'Computers and the Internet'},\n",
       "  {'is_major': 'N',\n",
       "   'name': 'subject',\n",
       "   'rank': '2',\n",
       "   'value': 'Entrepreneurship'},\n",
       "  {'is_major': 'N',\n",
       "   'name': 'organizations',\n",
       "   'rank': '3',\n",
       "   'value': 'Blackboard Incorporated'}],\n",
       " 'lead_paragraph': 'A start-up’s strategy resembles a diplomatic dance more than a hard-charging coup d’état.',\n",
       " 'pub_date': '2006-07-16T00:00:00Z',\n",
       " 'q_info': {'desire2learn': [{'q': {'api_key': 'c7ba2eac72924572152e63f4516210d7:14:72380734',\n",
       "     'begin_date': '19990101',\n",
       "     'end_date': '20141231',\n",
       "     'page': 0,\n",
       "     'term': '\"desire2learn\"'},\n",
       "    'snippet': 'to zero.” Even the company’s name sends a reassuring message. Most of its current rivals — companies like eCollege.com, <strong>Desire2Learn</strong>, and Jenzabar — have identities that underscore their roots in the Internet era. Not so Mr.',\n",
       "    'term_category': 2}]},\n",
       " 'section_name': 'Business Day',\n",
       " 'source': 'The New York Times',\n",
       " 'web_url': 'http://www.nytimes.com/2006/07/16/business/yourmoney/16mgmt.html'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
